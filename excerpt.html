--- 
layout: jimsmaintempl 
title: Jim Sweeney - Technologist 
---

<div class="intro-block book-cover">

	<br>
	<br>
	<br>
	<br>
	<br>
	<h2>Book Excerpt</h2>
	<br>
	<h3>An excerpt from the case study on</h3>
	<h3>Los Alamos National Labs.  They </h3>
	<h3>implemented a VMware vCloud based</h3>
	<h3>hybrid Cloud model within their Agency.</h3>
	<br>
	<br>
	<p>Today, Los Alamos National Labs has a more strategic focus on worker safety and security awareness. A variety of research programs support the Laboratory’s basic mission: maintaining the safety,
		security, and reliability of the nation’s nuclear deterrent without
		the need to return to underground testing. But what does that have to
		do with Cloud? Los Alamos National Labs was one of the first
		government agencies to implement a Hybrid Cloud. Not only were they
		one of the first government agencies, they were one of the first in
		the country – period! And the innovator behind it is already
		implementing it across several Department of Energy Labs. I recently
		interviewed Anil Karmel, Solutions Architect at Los Alamos and the
		architect of this project. He is the brains behind one of the first
		Hybrid Clouds in use today. In fact, he was so ahead of the curve that
		he actually worked with VMware to improve their vCloud product as it
		went through the beta testing process before general release to the
		public. To review, a Hybrid Cloud is a combination of an on-premise
		private or community Cloud (called a Cloud cell) and a public Cloud
		(another cell) managed as one large Cloud implementation. ￼I learned
		from Anil was that he did not start out to convert the entire agency.
		And he didn’t set out to build a Hybrid Cloud. He started by
		virtualizing his then-current infrastructure using VMware. Even at
		this stage in the evolutionary process, there were some good reasons
		to move to a Hybrid Cloud (figure 19-1). His first VMware cluster,
		assembled in 2006, consisted of thirteen HP ProLiant DL585 servers,
		each with 4 dual-core AMD Opteron processors, 32 GB of memory and
		redundant network and fiber channel cards. For storage, he used 250 TB
		of total storage shared across several HP EVA SAN devices. Anil saw
		the tremendous cost savings in power, cooling and space that were
		possible by virtualizing an infrastructure. He decommissioned 105
		physical servers and shut down 3 data centers just by virtualizing his
		existing infrastructure. Last, but certainly not least, Anil realized
		amazing electrical power savings from decommissioning physical servers
		and datacenters. The actual savings are shown in figure 19-2.</p>
	￼

	<p>The initial projection called for a return on investment (ROI)
		of two years, but the actual ROI he achieved was only nine months from
		the inception of the project! But why start with virtualization? In
		Anil’s opinion, “Leapfrogging virtualization to go to Cloud only means
		that you are setting yourself up for failure. Virtualize, then build
		best practices, understand what that means, then build the Cloud on
		top of that.” When he completed the virtualization project he then
		moved on to create the Hybrid Cloud environment, using his Private
		Cloud and the vCloud implementation of the public Cloud provider,
		Terremark. But what was Anil’s motivation? Hadn’t he already
		accomplished a lot with his virtualization cluster? He certainly had!
		But there were other requirements that came to light: Anil wanted a
		self-service web portal to automatically request and provision virtual
		servers He wanted the green IT savings dynamically computed and
		displayed on the website He wanted his cluster to include LifeCycle
		Management and Chargeback He wanted to support a variety of operating
		systems, including Microsoft Windows, Red Hat Enterprise Linux, and
		Sun Solaris. He also knew that in order to attract customers to his
		self-service environment, he would need to offer certain value-added
		services that were not automatically offered in a standard virtualized
		environment, including:</p>

	<ul>
		<li>Full backup/recovery of virtual machines</li>
		<li>vCenter Management consoled administrators to support the
			underlying infrastructure</li>
		<li>No ongoing infrastructure refresh costs</li>
		<li>New virtual servers automatically provisioned for the
			customer</li>
	</ul>

	<p>In practice, this meant that once the virtual machines were
		requested and provisioned from the self-service portal, all the user
		had to worry about was the security plan for the virtual machine and
		the system administration and maintenance of the operating system and
		the applications. The whole point was to use the principle of
		“Attraction” versus “Authoritarianism.” They practiced this principle
		in the design. Anil said that although they were not fully
		virtualized, they had designed a system “for the 80%.” In other words,
		while this system didn’t cover everyone’s needs at LANL, it met the
		needs of 80% of the users. For them, that was a huge success. Anil
		told me that there still are many physical servers left at Los Alamos.
		Many of those users elected to stay on them for one reason or another.
		Maybe they felt the difficulty of migrating their workload to a
		virtual environment outweighed the benefits. Or maybe they decided to
		stay on that physical machine until it was time for a refresh cycle.
		Anil decided that trying to design a system for 100% of the needs of
		the engineers at LANL was impossible. Rather than give up, he decided
		to design a system that was good for 80% of their needs. As you can
		tell from his savings numbers, even a system designed for 80% of the
		users can have a huge financial impact on an agency’s budget.</p>

</div>
</div>